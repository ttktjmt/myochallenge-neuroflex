{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HD5YE3jbQ3YO"
      },
      "source": [
        "## Setting the environment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJdm6gfuQqYS",
        "outputId": "f0cfc35f-4cec-49cc-d1f6-1ef2fb6b7184"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "libEGL warning: failed to open /dev/dri/renderD128: Permission denied\n",
            "\n",
            "libEGL warning: NEEDS EXTENSION: falling back to kms_swrast\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pygame 2.6.1 (SDL 2.28.4, Python 3.10.12)\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
            "MyoSuite:> Registering Myo Envs\n",
            "numpy version: 2.1.3\n"
          ]
        }
      ],
      "source": [
        "!pip install myosuite==2.8.3 --quiet\n",
        "!pip install \"stable-baselines3[extra]\" --quiet\n",
        "!pip install tqdm --quiet\n",
        "!pip install mujoco==3.1.2 --quiet\n",
        "!pip install sk-video --quiet\n",
        "!pip install wget --quiet\n",
        "import os\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "    current_dir = os.getcwd()\n",
        "    print(current_dir)\n",
        "    if current_dir == '/content':\n",
        "        !git clone https://github.com/ttktjmt/myochallenge-neuroflex.git\n",
        "        os.chdir('myochallenge-neuroflex')\n",
        "\n",
        "os.environ['MUJOCO_GL'] = 'egl'\n",
        "import mujoco\n",
        "import wget\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "import myosuite\n",
        "from myosuite.utils import gym\n",
        "import skvideo.io\n",
        "import numpy as np\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.callbacks import CheckpointCallback\n",
        "from tqdm.notebook import tqdm\n",
        "import importlib\n",
        "import envs\n",
        "import warnings\n",
        "from datetime import datetime\n",
        "from IPython.display import clear_output, Image, display\n",
        "import PIL.Image\n",
        "import numpy as np\n",
        "# the descrepancy of numpy version between the environment where the policy is trained and loaded can cause irrelevant issues\n",
        "print(f\"numpy version: {np.__version__}\")\n",
        "import os\n",
        "import skvideo.io"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZcidHz9Tf5E"
      },
      "source": [
        "## Define Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "q5iEl64VQ8Gk"
      },
      "outputs": [],
      "source": [
        "def show_video(video_path, video_width = 400):\n",
        "\n",
        "  video_file = open(video_path, \"r+b\").read()\n",
        "\n",
        "  video_url = f\"data:video/mp4;base64,{b64encode(video_file).decode()}\"\n",
        "  return HTML(f\"\"\"<video autoplay width={video_width} controls><source src=\"{video_url}\"></video>\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ji8-37YOUAkr"
      },
      "source": [
        "## Download baseline from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sgXPrO3gUAJT"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "--2024-11-22 13:15:19--  https://drive.google.com/uc?export=download&id=168S3oTBmXuf23zDDGMM3tCJ3HBnjYhsM\n",
            "Resolving drive.google.com (drive.google.com)... 172.217.31.142, 2404:6800:4004:825::200e\n",
            "Connecting to drive.google.com (drive.google.com)|172.217.31.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=168S3oTBmXuf23zDDGMM3tCJ3HBnjYhsM&export=download [following]\n",
            "--2024-11-22 13:15:20--  https://drive.usercontent.google.com/download?id=168S3oTBmXuf23zDDGMM3tCJ3HBnjYhsM&export=download\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 142.250.196.129, 2404:6800:4004:80a::2001\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|142.250.196.129|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3167662 (3.0M) [application/octet-stream]\n",
            "Saving to: ‘baseline.zip’\n",
            "\n",
            "     0K .......... .......... .......... .......... ..........  1%  626K 5s\n",
            "    50K .......... .......... .......... .......... ..........  3%  751K 4s\n",
            "   100K .......... .......... .......... .......... ..........  4% 3.67M 3s\n",
            "   150K .......... .......... .......... .......... ..........  6% 2.28M 3s\n",
            "   200K .......... .......... .......... .......... ..........  8% 2.61M 2s\n",
            "   250K .......... .......... .......... .......... ..........  9% 7.16M 2s\n",
            "   300K .......... .......... .......... .......... .......... 11% 1.48M 2s\n",
            "   350K .......... .......... .......... .......... .......... 12% 45.6M 2s\n",
            "   400K .......... .......... .......... .......... .......... 14% 17.3M 1s\n",
            "   450K .......... .......... .......... .......... .......... 16% 6.59M 1s\n",
            "   500K .......... .......... .......... .......... .......... 17% 9.63M 1s\n",
            "   550K .......... .......... .......... .......... .......... 19% 8.31M 1s\n",
            "   600K .......... .......... .......... .......... .......... 21% 8.20M 1s\n",
            "   650K .......... .......... .......... .......... .......... 22% 8.30M 1s\n",
            "   700K .......... .......... .......... .......... .......... 24% 10.1M 1s\n",
            "   750K .......... .......... .......... .......... .......... 25% 5.36M 1s\n",
            "   800K .......... .......... .......... .......... .......... 27% 8.15M 1s\n",
            "   850K .......... .......... .......... .......... .......... 29% 3.96M 1s\n",
            "   900K .......... .......... .......... .......... .......... 30% 4.20M 1s\n",
            "   950K .......... .......... .......... .......... .......... 32% 3.92M 1s\n",
            "  1000K .......... .......... .......... .......... .......... 33% 11.6M 1s\n",
            "  1050K .......... .......... .......... .......... .......... 35% 5.50M 1s\n",
            "  1100K .......... .......... .......... .......... .......... 37% 31.2M 1s\n",
            "  1150K .......... .......... .......... .......... .......... 38% 16.4M 1s\n",
            "  1200K .......... .......... .......... .......... .......... 40% 7.48M 1s\n",
            "  1250K .......... .......... .......... .......... .......... 42% 47.5M 0s\n",
            "  1300K .......... .......... .......... .......... .......... 43% 23.5M 0s\n",
            "  1350K .......... .......... .......... .......... .......... 45% 25.4M 0s\n",
            "  1400K .......... .......... .......... .......... .......... 46% 29.8M 0s\n",
            "  1450K .......... .......... .......... .......... .......... 48% 22.6M 0s\n",
            "  1500K .......... .......... .......... .......... .......... 50% 12.3M 0s\n",
            "  1550K .......... .......... .......... .......... .......... 51% 6.99M 0s\n",
            "  1600K .......... .......... .......... .......... .......... 53% 9.38M 0s\n",
            "  1650K .......... .......... .......... .......... .......... 54% 6.56M 0s\n",
            "  1700K .......... .......... .......... .......... .......... 56% 13.8M 0s\n",
            "  1750K .......... .......... .......... .......... .......... 58% 5.96M 0s\n",
            "  1800K ........."
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully downloaded baseline.zip\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ". .......... .......... .......... .......... 59% 4.57M 0s\n",
            "  1850K .......... .......... .......... .......... .......... 61% 17.2M 0s\n",
            "  1900K .......... .......... .......... .......... .......... 63% 27.1M 0s\n",
            "  1950K .......... .......... .......... .......... .......... 64% 13.5M 0s\n",
            "  2000K .......... .......... .......... .......... .......... 66% 9.14M 0s\n",
            "  2050K .......... .......... .......... .......... .......... 67% 6.96M 0s\n",
            "  2100K .......... .......... .......... .......... .......... 69% 10.5M 0s\n",
            "  2150K .......... .......... .......... .......... .......... 71% 11.1M 0s\n",
            "  2200K .......... .......... .......... .......... .......... 72% 9.24M 0s\n",
            "  2250K .......... .......... .......... .......... .......... 74% 9.21M 0s\n",
            "  2300K .......... .......... .......... .......... .......... 75% 7.06M 0s\n",
            "  2350K .......... .......... .......... .......... .......... 77% 9.61M 0s\n",
            "  2400K .......... .......... .......... .......... .......... 79% 8.33M 0s\n",
            "  2450K .......... .......... .......... .......... .......... 80% 8.18M 0s\n",
            "  2500K .......... .......... .......... .......... .......... 82% 12.6M 0s\n",
            "  2550K .......... .......... .......... .......... .......... 84% 8.24M 0s\n",
            "  2600K .......... .......... .......... .......... .......... 85% 8.28M 0s\n",
            "  2650K .......... .......... .......... .......... .......... 87% 11.2M 0s\n",
            "  2700K .......... .......... .......... .......... .......... 88% 8.53M 0s\n",
            "  2750K .......... .......... .......... .......... .......... 90% 9.91M 0s\n",
            "  2800K .......... .......... .......... .......... .......... 92% 4.96M 0s\n",
            "  2850K .......... .......... .......... .......... .......... 93% 23.0M 0s\n",
            "  2900K .......... .......... .......... .......... .......... 95% 9.20M 0s\n",
            "  2950K .......... .......... .......... .......... .......... 96% 9.27M 0s\n",
            "  3000K .......... .......... .......... .......... .......... 98% 9.01M 0s\n",
            "  3050K .......... .......... .......... .......... ...       100% 5.84M=0.5s\n",
            "\n",
            "2024-11-22 13:15:26 (5.60 MB/s) - ‘baseline.zip’ saved [3167662/3167662]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "file_id = '168S3oTBmXuf23zDDGMM3tCJ3HBnjYhsM'\n",
        "download_url = f'https://drive.google.com/uc?export=download&id={file_id}'\n",
        "target_file = 'baseline.zip'  # Change the file name and extension as needed\n",
        "\n",
        "os.system(f'wget --no-check-certificate \"{download_url}\" -O {target_file}')\n",
        "\n",
        "if os.path.exists(target_file):\n",
        "    print(f'Successfully downloaded {target_file}')\n",
        "else:\n",
        "    print('Failed to download the file')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cy48aX38V3Ap"
      },
      "source": [
        "## Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ztQcB4i3V7L_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m    MyoSuite: A contact-rich simulation suite for musculoskeletal motor control\n",
            "        Vittorio Caggiano, Huawei Wang, Guillaume Durandau, Massimo Sartori, Vikash Kumar\n",
            "        L4DC-2019 | https://sites.google.com/view/myosuite\n",
            "    \u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ta747375ki/myochallenge-neuroflex/venv/lib/python3.10/site-packages/gymnasium/envs/registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment CustomBimanualEnv-v0 already in registry.\u001b[0m\n",
            "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
            "/home/ta747375ki/myochallenge-neuroflex/venv/lib/python3.10/site-packages/myosuite/envs/myo/myochallenge/bimanual_v0.py:432: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  self.manip_joint_range = np.arange(model.joint(\"manip_object/freejoint\").qposadr,\n",
            "/home/ta747375ki/myochallenge-neuroflex/venv/lib/python3.10/site-packages/myosuite/envs/myo/myochallenge/bimanual_v0.py:432: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  self.manip_joint_range = np.arange(model.joint(\"manip_object/freejoint\").qposadr,\n",
            "/home/ta747375ki/myochallenge-neuroflex/venv/lib/python3.10/site-packages/myosuite/envs/myo/myochallenge/bimanual_v0.py:432: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  self.manip_joint_range = np.arange(model.joint(\"manip_object/freejoint\").qposadr,\n",
            "/home/ta747375ki/myochallenge-neuroflex/venv/lib/python3.10/site-packages/myosuite/envs/myo/myochallenge/bimanual_v0.py:435: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  self.manip_dof_range = np.arange(model.joint(\"manip_object/freejoint\").dofadr,\n",
            "/home/ta747375ki/myochallenge-neuroflex/venv/lib/python3.10/site-packages/myosuite/envs/myo/myochallenge/bimanual_v0.py:435: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  self.manip_dof_range = np.arange(model.joint(\"manip_object/freejoint\").dofadr,\n",
            "/home/ta747375ki/myochallenge-neuroflex/venv/lib/python3.10/site-packages/myosuite/envs/myo/myochallenge/bimanual_v0.py:435: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  self.manip_dof_range = np.arange(model.joint(\"manip_object/freejoint\").dofadr,\n",
            "/home/ta747375ki/myochallenge-neuroflex/venv/lib/python3.10/site-packages/myosuite/envs/myo/myochallenge/bimanual_v0.py:170: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  self.obj_vert_addr = np.arange(self.sim.model.mesh(self.obj_mid).vertadr,\n",
            "/home/ta747375ki/myochallenge-neuroflex/venv/lib/python3.10/site-packages/myosuite/envs/myo/myochallenge/bimanual_v0.py:170: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  self.obj_vert_addr = np.arange(self.sim.model.mesh(self.obj_mid).vertadr,\n",
            "/home/ta747375ki/myochallenge-neuroflex/venv/lib/python3.10/site-packages/myosuite/envs/myo/myochallenge/bimanual_v0.py:170: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  self.obj_vert_addr = np.arange(self.sim.model.mesh(self.obj_mid).vertadr,\n",
            "/home/ta747375ki/myochallenge-neuroflex/venv/lib/python3.10/site-packages/myosuite/envs/myo/myochallenge/bimanual_v0.py:172: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  q = self.sim.model.geom(self.obj_gid - 1).quat\n",
            "/home/ta747375ki/myochallenge-neuroflex/venv/lib/python3.10/site-packages/myosuite/envs/myo/myochallenge/bimanual_v0.py:176: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  self.sim.model.geom(self.obj_gid - 1).quat = [1, 0, 0, 0]\n",
            "/home/ta747375ki/myochallenge-neuroflex/venv/lib/python3.10/site-packages/myosuite/envs/myo/myochallenge/bimanual_v0.py:177: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  self.sim.model.mesh_vert[self.obj_vert_addr] += (self.sim.model.geom(self.obj_gid - 1).pos\n",
            "/home/ta747375ki/myochallenge-neuroflex/venv/lib/python3.10/site-packages/myosuite/envs/myo/myochallenge/bimanual_v0.py:178: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  - self.sim.model.geom(self.obj_gid).pos)[None, :]\n",
            "/home/ta747375ki/myochallenge-neuroflex/venv/lib/python3.10/site-packages/myosuite/envs/myo/myochallenge/bimanual_v0.py:180: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  self.sim.model.geom(self.obj_gid - 1).pos = self.sim.model.geom(self.obj_gid).pos\n",
            "/home/ta747375ki/myochallenge-neuroflex/venv/lib/python3.10/site-packages/myosuite/envs/myo/myochallenge/bimanual_v0.py:180: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  self.sim.model.geom(self.obj_gid - 1).pos = self.sim.model.geom(self.obj_gid).pos\n"
          ]
        }
      ],
      "source": [
        "importlib.reload(envs)\n",
        "env_name = 'myoChallengeBimanual-v0'\n",
        "env = gym.make(env_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OE0zSmINWElF",
        "outputId": "4cdd3d84-797e-419e-c7aa-8c3a1fb7ed08"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ta747375ki/myochallenge-neuroflex/venv/lib/python3.10/site-packages/stable_baselines3/common/save_util.py:165: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
            "  deserialized_object = cloudpickle.loads(base64_object)\n",
            "/home/ta747375ki/myochallenge-neuroflex/venv/lib/python3.10/site-packages/stable_baselines3/common/save_util.py:165: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
            "  deserialized_object = cloudpickle.loads(base64_object)\n",
            "/home/ta747375ki/myochallenge-neuroflex/venv/lib/python3.10/site-packages/stable_baselines3/common/save_util.py:165: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
            "  deserialized_object = cloudpickle.loads(base64_object)\n",
            "/home/ta747375ki/myochallenge-neuroflex/venv/lib/python3.10/site-packages/stable_baselines3/common/save_util.py:165: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
            "  deserialized_object = cloudpickle.loads(base64_object)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ta747375ki/myochallenge-neuroflex/venv/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.seed to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.seed` for environment variables or `env.get_wrapper_attr('seed')` that will search the reminding wrappers.\u001b[0m\n",
            "  logger.warn(\n"
          ]
        }
      ],
      "source": [
        "checkpoint_callback = CheckpointCallback(save_freq=50000, save_path='./logs/', name_prefix='ppo_model')\n",
        "# model_file_path = \"baseline.zip\"\n",
        "# model_file_path = \"logs/ppo_model_400000_steps.zip\"\n",
        "model_file_path = \"agent/model.zip\"\n",
        "\n",
        "if os.path.exists(model_file_path):\n",
        "    try:\n",
        "        model = PPO.load(model_file_path, env, device='cpu')\n",
        "        print(\"Model loaded successfully!\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model: {e}\")\n",
        "else:\n",
        "    print(\"Model file does not exist. Please train the model first.\")\n",
        "\n",
        "env.reset()\n",
        "env.seed(27) #setting a seed for the env\n",
        "tb_log_name = \"ppo_training\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFHhxLBX-a2G"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "sCPmGdmYdPXR"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ta747375ki/myochallenge-neuroflex/venv/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
            "  logger.warn(f\"{pre} is not within the observation space.\")\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/myochallenge-neuroflex/venv/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py:315\u001b[0m, in \u001b[0;36mPPO.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[1;32m    308\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    313\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    314\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[0;32m--> 315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/myochallenge-neuroflex/venv/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:300\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[0;32m--> 300\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m continue_training:\n\u001b[1;32m    303\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "File \u001b[0;32m~/myochallenge-neuroflex/venv/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:195\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;66;03m# Otherwise, clip the actions to avoid out of bound error\u001b[39;00m\n\u001b[1;32m    192\u001b[0m         \u001b[38;5;66;03m# as we are sampling from an unbounded Gaussian distribution\u001b[39;00m\n\u001b[1;32m    193\u001b[0m         clipped_actions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(actions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mlow, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mhigh)\n\u001b[0;32m--> 195\u001b[0m new_obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclipped_actions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mnum_envs\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# Give access to local variables\u001b[39;00m\n",
            "File \u001b[0;32m~/myochallenge-neuroflex/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:206\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[0;32m--> 206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/myochallenge-neuroflex/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:72\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m         obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvs[env_idx]\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_obs(env_idx, obs)\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obs_from_buf(), np\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews), np\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones), \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuf_infos\u001b[49m\u001b[43m)\u001b[49m)\n",
            "File \u001b[0;32m/usr/lib/python3.10/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
            "File \u001b[0;32m/usr/lib/python3.10/copy.py:206\u001b[0m, in \u001b[0;36m_deepcopy_list\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    204\u001b[0m append \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mappend\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x:\n\u001b[0;32m--> 206\u001b[0m     append(\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
            "File \u001b[0;32m/usr/lib/python3.10/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
            "File \u001b[0;32m/usr/lib/python3.10/copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
            "File \u001b[0;32m/usr/lib/python3.10/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model.learn(total_timesteps=500000, callback=checkpoint_callback, tb_log_name=tb_log_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3Mi3lAZ-eai"
      },
      "source": [
        "## Visualize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iy4aj3jTWM2S",
        "outputId": "a59ffa30-445e-443d-ec65-7b0a89f26de1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ta747375ki/myochallenge-neuroflex/venv/lib/python3.10/site-packages/myosuite/envs/myo/myochallenge/bimanual_v0.py:368: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  self.sim.model.geom(self.obj_gid).size = self.obj_size0 * obj_scales\n",
            "/home/ta747375ki/myochallenge-neuroflex/venv/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.obs_dict to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.obs_dict` for environment variables or `env.get_wrapper_attr('obs_dict')` that will search the reminding wrappers.\u001b[0m\n",
            "  logger.warn(\n",
            "/home/ta747375ki/myochallenge-neuroflex/venv/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.obsdict2obsvec to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.obsdict2obsvec` for environment variables or `env.get_wrapper_attr('obsdict2obsvec')` that will search the reminding wrappers.\u001b[0m\n",
            "  logger.warn(\n",
            "/home/ta747375ki/myochallenge-neuroflex/venv/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.obs_keys to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.obs_keys` for environment variables or `env.get_wrapper_attr('obs_keys')` that will search the reminding wrappers.\u001b[0m\n",
            "  logger.warn(\n",
            "/home/ta747375ki/myochallenge-neuroflex/venv/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.sim to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.sim` for environment variables or `env.get_wrapper_attr('sim')` that will search the reminding wrappers.\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 50\u001b[0m\n\u001b[1;32m     48\u001b[0m geom_1_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(env\u001b[38;5;241m.\u001b[39msim\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mgeom_group \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     49\u001b[0m env\u001b[38;5;241m.\u001b[39msim\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mgeom_rgba[geom_1_indices, \u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 50\u001b[0m frame \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrenderer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender_offscreen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcamera_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Clear previous output and display new frame\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# obj_qpos_list.append(obs_dict['object_qpos'])\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# pil_image = PIL.Image.fromarray(frame)\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# display(pil_image)\u001b[39;00m\n\u001b[1;32m     60\u001b[0m _frames\u001b[38;5;241m.\u001b[39mappend(frame)\n",
            "File \u001b[0;32m~/myochallenge-neuroflex/venv/lib/python3.10/site-packages/myosuite/renderer/mj_renderer.py:112\u001b[0m, in \u001b[0;36mMJRenderer.render_offscreen\u001b[0;34m(self, width, height, rgb, depth, segmentation, camera_id, device_id)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rgb:\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_renderer\u001b[38;5;241m.\u001b[39mupdate_scene(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sim\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mptr, camera\u001b[38;5;241m=\u001b[39mcamera_id, scene_option\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_scene_option)\n\u001b[0;32m--> 112\u001b[0m     rgb_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_renderer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m depth:\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_renderer\u001b[38;5;241m.\u001b[39menable_depth_rendering()\n",
            "File \u001b[0;32m~/myochallenge-neuroflex/venv/lib/python3.10/site-packages/mujoco/renderer.py:239\u001b[0m, in \u001b[0;36mRenderer.render\u001b[0;34m(self, out)\u001b[0m\n\u001b[1;32m    237\u001b[0m   np\u001b[38;5;241m.\u001b[39mcopyto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_scene\u001b[38;5;241m.\u001b[39mflags, original_flags)\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 239\u001b[0m   \u001b[43m_render\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmjr_readPixels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mjr_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m out[:] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mflipud(out)\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "warnings.filterwarnings(\"ignore\", message=\".*tostring.*is deprecated.*\")\n",
        "\n",
        "movie = True  # we want to save a video\n",
        "frames = []\n",
        "# view = 'front'\n",
        "# obj_qpos_list = []\n",
        "release_threshold = 0.08\n",
        "released_step = -1\n",
        "waiting_step1 = 100\n",
        "waiting_step2 = 150\n",
        "waiting_step3 = 200\n",
        "\n",
        "for _ in range(10):\n",
        "    ep_rewards = 0\n",
        "    done = False\n",
        "    obs = env.reset()\n",
        "    _frames = []\n",
        "    for step in range(300):\n",
        "        obs_dict = env.obs_dict\n",
        "        obs = env.obsdict2obsvec(obs_dict, env.obs_keys)[1]\n",
        "        action, _ = model.predict(obs, deterministic=True)\n",
        "        # myoHand control\n",
        "        action[30] = 1\n",
        "        obj_xpos = obs_dict['object_qpos'][0]\n",
        "        if obj_xpos > release_threshold and released_step == -1:\n",
        "            released_step = step\n",
        "\n",
        "        if step - released_step > waiting_step1:\n",
        "            action[32:40] = 0\n",
        "            action[40:49] = 1\n",
        "\n",
        "        # MPL control\n",
        "        action[-17:] = np.array([-0.65001469, 1., -0.23187843, 0.59583695, 0.92356688, -0.16,\n",
        "                                -0.28, -0.88, 0.25, -0.846, -0.24981132, -0.91823529,\n",
        "                                -0.945, -0.925, -0.929, -0.49, -0.18])\n",
        "        if step - released_step > waiting_step2:\n",
        "            action[-17:] = np.array([-0.4199236, 1., -0.9840558, 0.35299219, 0.92356688, 0.02095238,\n",
        "                                    -0.28, -0.88, 0.25, -0.846, -0.24981132, -0.91823529,\n",
        "                                    -0.945, -0.925, -0.929, -0.49, -0.918])\n",
        "        if step - released_step > waiting_step3:\n",
        "            action[-17:] = np.array([-0.4199236, 1., -0.9840558, 0.35299219, 0.3910828, 0.02095238,\n",
        "                                    -0.28, -0.88, 0.25, -0.846, -0.24981132, -0.91823529,\n",
        "                                    -0.945, -0.925, -0.929, -0.49, -0.918])\n",
        "\n",
        "        obs, reward, done, info, info_2 = env.step(action)\n",
        "        ep_rewards += reward  # Accumulate rewards for the episode\n",
        "        if movie:\n",
        "            geom_1_indices = np.where(env.sim.model.geom_group == 1)\n",
        "            env.sim.model.geom_rgba[geom_1_indices, 3] = 0\n",
        "            frame = env.sim.renderer.render_offscreen(width=400, height=400, camera_id=1)\n",
        "\n",
        "            # Clear previous output and display new frame\n",
        "            # obj_qpos_list.append(obs_dict['object_qpos'])\n",
        "\n",
        "            # Convert numpy array to PIL Image\n",
        "            # clear_output(wait=True)\n",
        "            # pil_image = PIL.Image.fromarray(frame)\n",
        "            # display(pil_image)\n",
        "\n",
        "            _frames.append(frame)\n",
        "    \n",
        "    print(f\"{ep_rewards = }\")\n",
        "    if ep_rewards > 0:\n",
        "        frames.extend(_frames)\n",
        "\n",
        "env.close()\n",
        "\n",
        "# Save video\n",
        "os.makedirs('videos', exist_ok=True)\n",
        "current_date = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "skvideo.io.vwrite(f'videos/test_policy_{current_date}.mp4',\n",
        "                  np.asarray(frames),\n",
        "                  inputdict={'-r': '100'},\n",
        "                  outputdict={\"-pix_fmt\": \"yuv420p\"})\n",
        "show_video(f'videos/test_policy_{current_date}.mp4')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
